{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f294d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"Must be using Python 3\")\n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "today = datetime.today()\n",
    "today = today.strftime('%B%d')\n",
    "outpath = '/project/chihway/raulteixeira/data/'\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "febd004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This will produce Nsamples X 64 samples\n",
    "Nsamples = int(2e3)\n",
    "\n",
    "#data_dir = '/global/cscratch1/sd/aamon/sompz_data/v0.50/'\n",
    "\n",
    "#redshift_sample_dir = data_dir\n",
    "#redshift_file_name = 'redshift_deep_balrog_incl_cell_assignment'\n",
    "#redshift_sample_dir = '/global/cscratch1/sd/aamon/sompz_data/zsamples/'\n",
    "#redshift_file_name = 'PhOpt_PAU_C30elsewhere_deep_balrog'\n",
    "#redshift_file_name = 'opt_spec_C30elsewhere_deep_balrog'\n",
    "redshift_file_name =  'optPrime_spec_PAU_C30elsewhere_deep_balrog'\n",
    "\n",
    "\n",
    "# out_path = f'/global/cscratch1/sd/alexalar/desy3data/Nz_samples/v0.50/3sdir_fid_zsamples_test1/{redshift_file_name}/'\n",
    "\n",
    "# if not os.path.exists(out_path):\n",
    "#     os.makedirs(out_path)\n",
    "\n",
    "\n",
    "\n",
    "### Comment this line if you don't want to save the summary h5 file.\n",
    "save_h5 = f'/project/chihway/raulteixeira/data/SOMPZ_{redshift_file_name}_{today}.h5'\n",
    "    \n",
    "#####################################\n",
    "### Load catalogs and essential matrices.\n",
    "#####################################\n",
    "    \n",
    "### Balrog files ###\n",
    "# balrog_file= data_dir + 'deep_balrog_incl_cell_assignment_incw.pkl'\n",
    "# balrog_file2= data_dir + 'deep_balrog_incl_cell_assignment_incw2.pkl'\n",
    "\n",
    "# balrog_data1= pickle.load(open(balrog_file, 'rb'), encoding='latin1')\n",
    "# balrog_data2= pickle.load(open(balrog_file2, 'rb'), encoding='latin1')\n",
    "# balrog_data=pd.concat([balrog_data1, balrog_data2], ignore_index=True)\n",
    "# ## This computes the lensingXresponse weight for each galaxy, removing the Balrog injection rate.\n",
    "# balrog_data['weight_response_shear'] = balrog_data['injection_counts']*balrog_data['overlap_weight']\n",
    "\n",
    "\n",
    "# spec_file= redshift_sample_dir +'%s.pkl'%redshift_file_name\n",
    "# spec_file2= redshift_sample_dir +'%s2.pkl'%redshift_file_name\n",
    "# spec_data1= pickle.load(open(spec_file, 'rb'), encoding='latin1')\n",
    "# spec_data2= pickle.load(open(spec_file2, 'rb'), encoding='latin1')\n",
    "# spec_data=pd.concat([spec_data1, spec_data2], ignore_index=True)\n",
    "\n",
    "## Add the overlap_weight to the redshift sample\n",
    "\n",
    "# needed_columns = ['overlap_weight','cell_deep', 'cell_wide_unsheared']\n",
    "# needed_columns = [x for x in needed_columns if x not in spec_data.columns.values]\n",
    "\n",
    "# spec_data = spec_data.merge(balrog_data[['bal_id']+needed_columns], on='bal_id')\n",
    "spec_data = pd.read_hdf('%s/DES_DF_baldet_121923_64x64_cells_with_redshifts_colnames4uncertainties_corrected.hdf'%outpath, key='df') #is this the catalog with just objects that have redshifts?? - Raul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbedc4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_ra</th>\n",
       "      <th>true_dec</th>\n",
       "      <th>injection_counts</th>\n",
       "      <th>overlap_weight</th>\n",
       "      <th>true_id</th>\n",
       "      <th>id</th>\n",
       "      <th>tilename</th>\n",
       "      <th>Z</th>\n",
       "      <th>cell_deep</th>\n",
       "      <th>cell_wide_unsheared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112.125237</td>\n",
       "      <td>28.332273</td>\n",
       "      <td>19</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>712517969</td>\n",
       "      <td>0</td>\n",
       "      <td>b'DES0726+2834'</td>\n",
       "      <td>0.539000</td>\n",
       "      <td>1363.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112.125221</td>\n",
       "      <td>28.345119</td>\n",
       "      <td>32</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>712734329</td>\n",
       "      <td>0</td>\n",
       "      <td>b'DES0726+2834'</td>\n",
       "      <td>0.729000</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112.125313</td>\n",
       "      <td>28.351561</td>\n",
       "      <td>31</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>712633934</td>\n",
       "      <td>-99</td>\n",
       "      <td>b'DES0726+2834'</td>\n",
       "      <td>0.719308</td>\n",
       "      <td>2303.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112.125336</td>\n",
       "      <td>28.36438</td>\n",
       "      <td>46</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>712506387</td>\n",
       "      <td>12308</td>\n",
       "      <td>b'DES0726+2834'</td>\n",
       "      <td>0.737000</td>\n",
       "      <td>2848.0</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112.125351</td>\n",
       "      <td>28.377209</td>\n",
       "      <td>22</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>699329755</td>\n",
       "      <td>-99</td>\n",
       "      <td>b'DES0726+2834'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2788.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380473</th>\n",
       "      <td>248.832443</td>\n",
       "      <td>10.169336</td>\n",
       "      <td>36</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>699639891</td>\n",
       "      <td>46390</td>\n",
       "      <td>b'DES1636+1000'</td>\n",
       "      <td>0.228830</td>\n",
       "      <td>936.0</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380474</th>\n",
       "      <td>248.832382</td>\n",
       "      <td>10.175707</td>\n",
       "      <td>30</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>692161566</td>\n",
       "      <td>-99</td>\n",
       "      <td>b'DES1636+1000'</td>\n",
       "      <td>0.249112</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380475</th>\n",
       "      <td>248.832413</td>\n",
       "      <td>10.188523</td>\n",
       "      <td>19</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>712385835</td>\n",
       "      <td>-99</td>\n",
       "      <td>b'DES1636+1000'</td>\n",
       "      <td>0.297766</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380476</th>\n",
       "      <td>248.832352</td>\n",
       "      <td>10.227047</td>\n",
       "      <td>13</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>699700931</td>\n",
       "      <td>-99</td>\n",
       "      <td>b'DES1636+1000'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2839.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380477</th>\n",
       "      <td>248.832336</td>\n",
       "      <td>10.239907</td>\n",
       "      <td>6</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>691937308</td>\n",
       "      <td>52126</td>\n",
       "      <td>b'DES1636+1000'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2577.0</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3380478 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            true_ra   true_dec  injection_counts  overlap_weight    true_id  \\\n",
       "0        112.125237  28.332273                19        0.052632  712517969   \n",
       "1        112.125221  28.345119                32        0.031250  712734329   \n",
       "2        112.125313  28.351561                31        0.032258  712633934   \n",
       "3        112.125336   28.36438                46        0.021739  712506387   \n",
       "4        112.125351  28.377209                22        0.045455  699329755   \n",
       "...             ...        ...               ...             ...        ...   \n",
       "3380473  248.832443  10.169336                36        0.027778  699639891   \n",
       "3380474  248.832382  10.175707                30        0.033333  692161566   \n",
       "3380475  248.832413  10.188523                19        0.052632  712385835   \n",
       "3380476  248.832352  10.227047                13        0.076923  699700931   \n",
       "3380477  248.832336  10.239907                 6        0.166667  691937308   \n",
       "\n",
       "            id         tilename         Z  cell_deep  cell_wide_unsheared  \n",
       "0            0  b'DES0726+2834'  0.539000     1363.0                    0  \n",
       "1            0  b'DES0726+2834'  0.729000     1924.0                    0  \n",
       "2          -99  b'DES0726+2834'  0.719308     2303.0                    0  \n",
       "3        12308  b'DES0726+2834'  0.737000     2848.0                  337  \n",
       "4          -99  b'DES0726+2834'       NaN     2788.0                    0  \n",
       "...        ...              ...       ...        ...                  ...  \n",
       "3380473  46390  b'DES1636+1000'  0.228830      936.0                  629  \n",
       "3380474    -99  b'DES1636+1000'  0.249112     1017.0                    0  \n",
       "3380475    -99  b'DES1636+1000'  0.297766     1980.0                    0  \n",
       "3380476    -99  b'DES1636+1000'       NaN     2839.0                    0  \n",
       "3380477  52126  b'DES1636+1000'       NaN     2577.0                  805  \n",
       "\n",
       "[3380478 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0968fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_data['cell_deep']=spec_data['cell_deep'].astype(int)\n",
    "spec_data['cell_wide_unsheared']=spec_data['cell_wide_unsheared'].astype(int)\n",
    "spec_data['overlap_weight']=np.ones_like(spec_data['overlap_weight'])\n",
    "\n",
    "# ## This computes the lensingXresponse weight for each galaxy, removing the Balrog injection rate.\n",
    "spec_data['weight_response_shear'] = spec_data['injection_counts']*spec_data['overlap_weight']\n",
    "\n",
    "### Load dictionary containing which wide cells belong to which tomographic bin\n",
    "tomo_bins_wide_modal_even = pickle.load(open('%s/tomo_bins_wide_cells.pickle'%outpath, 'rb'), encoding='latin1')\n",
    "\n",
    "### Load p(chat) with all weights included: Balrog, response, shear.\n",
    "#pchat = np.load(data_dir+'pchat_modal_even.npy')\n",
    "pchat = np.load('%s/p_c_hat_bal_01092023.npz'%outpath)['p_c_hat_bal'].flatten() #here I don't have response nor shear weights\n",
    "\n",
    "### Load p(c|chat) with all weights included: Balrog, response, shear.\n",
    "pc_chat = np.load('%s/p_cchat_01092023.npz'%outpath)['p_cchat'].T\n",
    "#COMMENTED OUT UNTIL WE GET SHEAR WEIGHTS\n",
    "# pcchat = np.zeros_like(pc_chat)\n",
    "# np.add.at(pcchat, \n",
    "#           (spec_data.cell_deep.values.astype(int),spec_data.cell_wide_unsheared.values.astype(int)),\n",
    "#           spec_data.overlap_weight.values)\n",
    "# #pc_chat = pcchat/np.sum(pcchat,axis=0)\n",
    "# pc_chat_new = pcchat/np.sum(pcchat,axis=0)\n",
    "#\n",
    "#assert np.allclose(pc_chat_new,pc_chat)\n",
    "\n",
    "### Define the redshift binning. This is currently set by the sample variance.\n",
    "\n",
    "min_z   = 0.01\n",
    "max_z   = 5\n",
    "delta_z = 0.05\n",
    "zbins   = np.arange(min_z,max_z+delta_z,delta_z)\n",
    "zbinsc  = zbins[:-1]+(zbins[1]-zbins[0])/2.\n",
    "\n",
    "\n",
    "#####################################\n",
    "### compute N(z,c) and N(c), R(z,c), R(c) \n",
    "### and bin conditionalization versions.\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa5e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_Nzc(df):\n",
    "    \"\"\"\n",
    "    - This function returns the counts Nzc=N(z,c) in each bin z and cell c.\n",
    "    - The input is a pandas Dataframe containing a redshift sample. \n",
    "    - The redshift sample must have redshift and deep cell assignment.\n",
    "    - It computes the balrog probability defined as #detections/#injections \n",
    "    to weight the counts of each galaxy in N(z,c).\n",
    "    \"\"\"\n",
    "\n",
    "    redshift_sample = df[['injection_counts','true_id','cell_deep', 'Z']].groupby('true_id').agg('mean').reset_index()\n",
    "    unique_id, unique_counts = np.unique(df.true_id.values, return_counts=True)\n",
    "    redshift_sample = redshift_sample.merge(pd.DataFrame({'true_id':unique_id, 'unique_counts':unique_counts}),on='true_id')\n",
    "    redshift_sample['balrog_prob'] = redshift_sample['unique_counts']/redshift_sample['injection_counts']\n",
    "    zid = np.digitize(redshift_sample.Z.values, zbins)-1\n",
    "    zid = np.clip(zid, 0, len(zbinsc)-1)\n",
    "    redshift_sample['zid'] = zid\n",
    "    redshift_sample_groupby = redshift_sample[['balrog_prob','zid','cell_deep']].groupby(['zid','cell_deep']).agg('sum')\n",
    "\n",
    "    Nzc = np.zeros((len(zbins)-1,64*64))\n",
    "    for index, row in redshift_sample_groupby.iterrows():\n",
    "        if (index[0]<0)|(index[0]>len(zbins)-1): continue\n",
    "        Nzc[int(index[0]),int(index[1])] = row.balrog_prob\n",
    "    return Nzc\n",
    "\n",
    "def return_Nc(df):\n",
    "    \"\"\"\n",
    "    - This function returns the counts Nc=N(c) in each cell c.\n",
    "    - The input is a pandas Dataframe containing a deep sample. \n",
    "    - The deep sample must have a deep cell assignment.\n",
    "    - It computes the balrog probability defined as #detections/#injections \n",
    "    to weight the counts of each galaxy in N(c).\n",
    "    \"\"\"\n",
    "\n",
    "    redshift_sample = df[['injection_counts','true_id','cell_deep']].groupby('true_id').agg('mean').reset_index()\n",
    "    unique_id, unique_counts = np.unique(df.true_id.values, return_counts=True)\n",
    "    redshift_sample = redshift_sample.merge(pd.DataFrame({'true_id':unique_id, 'unique_counts':unique_counts}),on='true_id')\n",
    "    redshift_sample['balrog_prob'] = redshift_sample['unique_counts']/redshift_sample['injection_counts']\n",
    "    redshift_sample_groupby = redshift_sample[['balrog_prob','cell_deep']].groupby(['cell_deep']).agg('sum')\n",
    "\n",
    "    Nc = np.zeros((64*64))\n",
    "    for index, row in redshift_sample_groupby.iterrows():\n",
    "        Nc[int(index)] = row.balrog_prob\n",
    "    return Nc\n",
    "\n",
    "def return_Rzc(df):\n",
    "    \"\"\"\n",
    "    - This function returns the average lensingXshear weight in each bin z and cell c, Rzc= <ResponseXshear>(z,c)\n",
    "    - The average is weighted by the balrog probability of each galaxy, defined as #detections/#injections.\n",
    "    \"\"\"\n",
    "    redshift_sample = df[['injection_counts','true_id','cell_deep', 'Z', 'weight_response_shear','overlap_weight']].groupby('true_id').agg('mean').reset_index()\n",
    "    unique_id, unique_counts = np.unique(df.true_id.values, return_counts=True)\n",
    "    redshift_sample = redshift_sample.merge(pd.DataFrame({'true_id':unique_id, 'unique_counts':unique_counts}),on='true_id')\n",
    "    redshift_sample['balrog_prob'] = redshift_sample['unique_counts']/redshift_sample['injection_counts']\n",
    "    zid = np.digitize(redshift_sample.Z.values, zbins)-1\n",
    "    zid = np.clip(zid, 0, len(zbinsc)-1)\n",
    "    redshift_sample['zid'] = zid\n",
    "    redshift_sample['weight_response_shear_balrogprob'] = redshift_sample['weight_response_shear']*redshift_sample['balrog_prob']\n",
    "\n",
    "\n",
    "    redshift_sample_groupby = redshift_sample[['weight_response_shear_balrogprob', 'balrog_prob','zid','cell_deep']].groupby(['zid','cell_deep']).agg('sum')\n",
    "    Rzc = np.zeros((len(zbins)-1,64*64))\n",
    "    for index, row in redshift_sample_groupby.iterrows():\n",
    "        if (index[0]<0)|(index[0]>len(zbins)-1): continue\n",
    "        Rzc[int(index[0]),int(index[1])] = row.weight_response_shear_balrogprob/row.balrog_prob\n",
    "    return Rzc\n",
    "\n",
    "def return_Rc(df):\n",
    "    \"\"\"\n",
    "    - This function returns the average lensingXshear weight in each cell c, Rc= <ResponseXshear>(c)\n",
    "    - The average is weighted by the balrog probability of each galaxy, defined as #detections/#injections.\n",
    "    \"\"\"\n",
    "    redshift_sample = df[['injection_counts','true_id','cell_deep', 'weight_response_shear','overlap_weight']].groupby('true_id').agg('mean').reset_index()\n",
    "    unique_id, unique_counts = np.unique(df.true_id.values, return_counts=True)\n",
    "    redshift_sample = redshift_sample.merge(pd.DataFrame({'true_id':unique_id, 'unique_counts':unique_counts}),on='true_id')\n",
    "    redshift_sample['balrog_prob'] = redshift_sample['unique_counts']/redshift_sample['injection_counts']\n",
    "    redshift_sample['weight_response_shear_balrogprob'] = redshift_sample['weight_response_shear']*redshift_sample['balrog_prob']\n",
    "\n",
    "\n",
    "    redshift_sample_groupby = redshift_sample[['weight_response_shear_balrogprob', 'balrog_prob','cell_deep']].groupby(['cell_deep']).agg('sum')\n",
    "    Rc = np.zeros(64*64)\n",
    "    for index, row in redshift_sample_groupby.iterrows():\n",
    "        Rc[int(index)] = row.weight_response_shear_balrogprob/row.balrog_prob\n",
    "    return Rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc43228",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Counts in the redshift sample (weighted by balrog, but not weighted by responseXlensing weights.)\n",
    "### Including condition on tomographic bin.\n",
    "Nzc = return_Nzc(spec_data)\n",
    "Nzc_0 = return_Nzc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[0])])\n",
    "Nzc_1 = return_Nzc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[1])])\n",
    "Nzc_2 = return_Nzc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[2])])\n",
    "Nzc_3 = return_Nzc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1d1692",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Counts in the deep sample (weighted by balrog, but not weighted by responseXlensing weights.)\n",
    "### Including condition on tomographic bin.\n",
    "Nc = return_Nc(spec_data)\n",
    "Nc_0 = return_Nc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[0])])\n",
    "Nc_1 = return_Nc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[1])])\n",
    "Nc_2 = return_Nc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[2])])\n",
    "Nc_3 = return_Nc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34feaa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "### If after the bin condition there are no redshift counts in a deep cell, don't apply the bin condition in that deep cell.\n",
    "sel_0 = ((np.sum(Nzc, axis=0)>0) & (np.sum(Nzc_0, axis=0)==0))\n",
    "sel_1 = ((np.sum(Nzc, axis=0)>0) & (np.sum(Nzc_1, axis=0)==0))\n",
    "sel_2 = ((np.sum(Nzc, axis=0)>0) & (np.sum(Nzc_2, axis=0)==0))\n",
    "sel_3 = ((np.sum(Nzc, axis=0)>0) & (np.sum(Nzc_3, axis=0)==0))\n",
    "Nzc_0[:,sel_0] = Nzc[:,sel_0].copy()\n",
    "Nzc_1[:,sel_1] = Nzc[:,sel_1].copy()\n",
    "Nzc_2[:,sel_2] = Nzc[:,sel_2].copy()\n",
    "Nzc_3[:,sel_3] = Nzc[:,sel_3].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38ce7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Average responseXlensing in each deep cell and redshift bin. The responseXlensing of each galaxy is weighted by its balrog probability.\n",
    "### Including condition on tomographic bin.\n",
    "\n",
    "Rzc = return_Rzc(spec_data)\n",
    "Rzc_0 = return_Rzc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[0])])\n",
    "Rzc_1 = return_Rzc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[1])])\n",
    "Rzc_2 = return_Rzc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[2])])\n",
    "Rzc_3 = return_Rzc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc1b6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Average responseXlensing in each deep cell in the REDSHIFT sample. The responseXlensing of each galaxy is weighted by its balrog probability.\n",
    "### Including condition on tomographic bin.\n",
    "Rc_redshift = return_Rc(spec_data)\n",
    "Rc_0_redshift = return_Rc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[0])])\n",
    "Rc_1_redshift = return_Rc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[1])])\n",
    "Rc_2_redshift = return_Rc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[2])])\n",
    "Rc_3_redshift = return_Rc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "429e28e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Average responseXlensing in each deep cell in the DEEP sample. The responseXlensing of each galaxy is weighted by its balrog probability.\n",
    "### Including condition on tomographic bin.\n",
    "Rc_deep = return_Rc(spec_data)\n",
    "Rc_0_deep = return_Rc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[0])])\n",
    "Rc_1_deep = return_Rc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[1])])\n",
    "Rc_2_deep = return_Rc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[2])])\n",
    "Rc_3_deep = return_Rc(spec_data[spec_data.cell_wide_unsheared.isin(tomo_bins_wide_modal_even[3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d3d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We do not need the balrog and redshift samples. We can delete them.\n",
    "# del spec_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "042df61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_bincondition_fraction_Nzt_redshiftsample(redshift_sample_Nzt):\n",
    "    \"\"\"This function returns the fraction of counts in Nzt with over \n",
    "    without bin condition, for each tomographic bin.\n",
    "    \"\"\"\n",
    "    pz_c_0 = redshift_sample_Nzt[0]/np.sum(redshift_sample_Nzt[0],axis=0)\n",
    "    pz_c_1 = redshift_sample_Nzt[1]/np.sum(redshift_sample_Nzt[1],axis=0)\n",
    "    pz_c_2 = redshift_sample_Nzt[2]/np.sum(redshift_sample_Nzt[2],axis=0)\n",
    "    pz_c_3 = redshift_sample_Nzt[3]/np.sum(redshift_sample_Nzt[3],axis=0)\n",
    "    pz_c_4 = redshift_sample_Nzt[4]/np.sum(redshift_sample_Nzt[4],axis=0)\n",
    "    \n",
    "    pz_c_0[~np.isfinite(pz_c_0)] = 0\n",
    "    pz_c_1[~np.isfinite(pz_c_1)] = 0\n",
    "    pz_c_2[~np.isfinite(pz_c_2)] = 0\n",
    "    pz_c_3[~np.isfinite(pz_c_3)] = 0\n",
    "    pz_c_4[~np.isfinite(pz_c_4)] = 0\n",
    "    \n",
    "    gzt_0 = pz_c_1/pz_c_0\n",
    "    gzt_1 = pz_c_2/pz_c_0\n",
    "    gzt_2 = pz_c_3/pz_c_0\n",
    "    gzt_3 = pz_c_4/pz_c_0\n",
    "\n",
    "\n",
    "    gzt_0[~np.isfinite(gzt_0)] = 0\n",
    "    gzt_1[~np.isfinite(gzt_1)] = 0\n",
    "    gzt_2[~np.isfinite(gzt_2)] = 0\n",
    "    gzt_3[~np.isfinite(gzt_3)] = 0\n",
    "    \n",
    "    return np.array([gzt_0, gzt_1, gzt_2, gzt_3])\n",
    "\n",
    "\n",
    "def return_bincondition_fraction_Nt_deepsample(deep_sample_Nt):\n",
    "    \"\"\"This function returns the fraction of counts in Nt with over \n",
    "    without bin condition, for each tomographic bin. Deep sample.\n",
    "    \"\"\"    \n",
    "    gt_0 = deep_sample_Nt[1]/deep_sample_Nt[0]\n",
    "    gt_1 = deep_sample_Nt[2]/deep_sample_Nt[0]\n",
    "    gt_2 = deep_sample_Nt[3]/deep_sample_Nt[0]\n",
    "    gt_3 = deep_sample_Nt[4]/deep_sample_Nt[0]\n",
    "\n",
    "    gt_0[~np.isfinite(gt_0)] = 0\n",
    "    gt_1[~np.isfinite(gt_1)] = 0\n",
    "    gt_2[~np.isfinite(gt_2)] = 0\n",
    "    gt_3[~np.isfinite(gt_3)] = 0\n",
    "\n",
    "    return np.array([gt_0, gt_1, gt_2, gt_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c0de5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:5: RuntimeWarning: invalid value encountered in divide\n",
      "  pz_c_0 = redshift_sample_Nzt[0]/np.sum(redshift_sample_Nzt[0],axis=0)\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:6: RuntimeWarning: invalid value encountered in divide\n",
      "  pz_c_1 = redshift_sample_Nzt[1]/np.sum(redshift_sample_Nzt[1],axis=0)\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:7: RuntimeWarning: invalid value encountered in divide\n",
      "  pz_c_2 = redshift_sample_Nzt[2]/np.sum(redshift_sample_Nzt[2],axis=0)\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "  pz_c_3 = redshift_sample_Nzt[3]/np.sum(redshift_sample_Nzt[3],axis=0)\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:9: RuntimeWarning: invalid value encountered in divide\n",
      "  pz_c_4 = redshift_sample_Nzt[4]/np.sum(redshift_sample_Nzt[4],axis=0)\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:17: RuntimeWarning: divide by zero encountered in divide\n",
      "  gzt_0 = pz_c_1/pz_c_0\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  gzt_0 = pz_c_1/pz_c_0\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:18: RuntimeWarning: divide by zero encountered in divide\n",
      "  gzt_1 = pz_c_2/pz_c_0\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  gzt_1 = pz_c_2/pz_c_0\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:19: RuntimeWarning: divide by zero encountered in divide\n",
      "  gzt_2 = pz_c_3/pz_c_0\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "  gzt_2 = pz_c_3/pz_c_0\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:20: RuntimeWarning: divide by zero encountered in divide\n",
      "  gzt_3 = pz_c_4/pz_c_0\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:20: RuntimeWarning: invalid value encountered in divide\n",
      "  gzt_3 = pz_c_4/pz_c_0\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:35: RuntimeWarning: invalid value encountered in divide\n",
      "  gt_0 = deep_sample_Nt[1]/deep_sample_Nt[0]\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:36: RuntimeWarning: invalid value encountered in divide\n",
      "  gt_1 = deep_sample_Nt[2]/deep_sample_Nt[0]\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:37: RuntimeWarning: invalid value encountered in divide\n",
      "  gt_2 = deep_sample_Nt[3]/deep_sample_Nt[0]\n",
      "/tmp/jobs/33065071/ipykernel_224404/647369091.py:38: RuntimeWarning: invalid value encountered in divide\n",
      "  gt_3 = deep_sample_Nt[4]/deep_sample_Nt[0]\n"
     ]
    }
   ],
   "source": [
    "fraction_Nzt = return_bincondition_fraction_Nzt_redshiftsample(np.array([Nzc, Nzc_0, Nzc_1, Nzc_2, Nzc_3]))\n",
    "fraction_Nt_D = return_bincondition_fraction_Nt_deepsample(np.array([Nc, Nc_0, Nc_1, Nc_2, Nc_3]))\n",
    "bincond_combined = fraction_Nzt*fraction_Nt_D[:,None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dce6380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_bincondition_weight_Rzt_combined(redshift_sample_Rzt, redshift_sample_Rt, deep_sample_Rt):\n",
    "    \"\"\"This function returns the final average responseXshear weight in each deep cell and redshift bin: Rzc.\n",
    "    Response weight = Response to shear of the balrog injection of a deep galaxy.\n",
    "    Shear weight = Weight to optimize of signal to noise of some shear observable. \n",
    "    - final Rzt = <Rzt>r * <Rt>r / <Rt>d\n",
    "    where: \n",
    "    - <Rzt>r: average weight in z,c in the redshift sample.\n",
    "    - <Rt>r: average weight in c in the redshift sample.\n",
    "    - <Rt>d: average weight in c in the deep sample.\n",
    "    It basically rescales the weight in Rzt such that it matches the average weight according to the deep sample.\n",
    "    \"\"\"    \n",
    "    Rzt_factor_0 = deep_sample_Rt[1]/redshift_sample_Rt[1]\n",
    "    Rzt_factor_1 = deep_sample_Rt[2]/redshift_sample_Rt[2]\n",
    "    Rzt_factor_2 = deep_sample_Rt[3]/redshift_sample_Rt[3]\n",
    "    Rzt_factor_3 = deep_sample_Rt[4]/redshift_sample_Rt[4]\n",
    "\n",
    "    Rzt_factor_0[~np.isfinite(Rzt_factor_0)] = 0\n",
    "    Rzt_factor_1[~np.isfinite(Rzt_factor_1)] = 0\n",
    "    Rzt_factor_2[~np.isfinite(Rzt_factor_2)] = 0\n",
    "    Rzt_factor_3[~np.isfinite(Rzt_factor_3)] = 0\n",
    "\n",
    "    Rzt_0_final = np.einsum('zt,t->zt', redshift_sample_Rzt[1], Rzt_factor_0)\n",
    "    Rzt_1_final = np.einsum('zt,t->zt', redshift_sample_Rzt[2], Rzt_factor_1)\n",
    "    Rzt_2_final = np.einsum('zt,t->zt', redshift_sample_Rzt[3], Rzt_factor_2)\n",
    "    Rzt_3_final = np.einsum('zt,t->zt', redshift_sample_Rzt[4], Rzt_factor_3)\n",
    "    return np.array([Rzt_0_final, Rzt_1_final, Rzt_2_final, Rzt_3_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f7a13a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/jobs/33065071/ipykernel_224404/1926104221.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  Rzt_factor_0 = deep_sample_Rt[1]/redshift_sample_Rt[1]\n",
      "/tmp/jobs/33065071/ipykernel_224404/1926104221.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  Rzt_factor_1 = deep_sample_Rt[2]/redshift_sample_Rt[2]\n",
      "/tmp/jobs/33065071/ipykernel_224404/1926104221.py:14: RuntimeWarning: invalid value encountered in divide\n",
      "  Rzt_factor_2 = deep_sample_Rt[3]/redshift_sample_Rt[3]\n",
      "/tmp/jobs/33065071/ipykernel_224404/1926104221.py:15: RuntimeWarning: invalid value encountered in divide\n",
      "  Rzt_factor_3 = deep_sample_Rt[4]/redshift_sample_Rt[4]\n"
     ]
    }
   ],
   "source": [
    "redshift_sample_Rzt = np.array([Rzc, Rzc_0, Rzc_1, Rzc_2, Rzc_3])\n",
    "redshift_sample_Rt = np.array([Rc_redshift, Rc_0_redshift, Rc_1_redshift, Rc_2_redshift, Rc_3_redshift])\n",
    "deep_sample_Rt = np.array([Rc_deep, Rc_0_deep, Rc_1_deep, Rc_2_deep, Rc_3_deep])\n",
    "Rt_combined = return_bincondition_weight_Rzt_combined(redshift_sample_Rzt, redshift_sample_Rt, deep_sample_Rt)\n",
    "\n",
    "\n",
    "#####################################\n",
    "### Load Sample Variance from theory. \n",
    "### Compute superphenotypes and N(T,c,Z) matrices.\n",
    "#####################################\n",
    "\n",
    "### Load the sample variance theory ingredient. This estimates the ratio between Shot noise and sample variance.\n",
    "\n",
    "#sv_th = np.load('/global/cscratch1/sd/alexalar/desy3data/cosmos_sample_variance.npy')[0]\n",
    "sv_th = np.load('/project/chihway/dhayaa/DECADE/Alex_NERSC_files/cosmos_sample_variance.npy')[0]\n",
    "sv_th = np.diagonal(sv_th)[:]\n",
    "sv_th = sv_th[:len(zbinsc)]\n",
    "assert sv_th.shape[0]==len(zbinsc)\n",
    "#sv_th_new = np.load('/global/cscratch1/sd/alexalar/desy3data/marco_sv_v2/sample_variance.npy')\n",
    "sv_th_new = np.load('/project/chihway/dhayaa/DECADE/Alex_NERSC_files/sample_variance.npy')\n",
    "sv_th_new_diag = np.array([np.diagonal(x) for x in sv_th_new])\n",
    "\n",
    "sv_th_new_final = np.linalg.pinv(np.sum(np.array([np.linalg.pinv(x) for x in sv_th_new]),axis=0))\n",
    "sv_th_new_final_diag = np.diagonal(sv_th_new_final)\n",
    "\n",
    "sv_th_new_diag = sv_th_new_diag[:,:len(zbinsc)]\n",
    "sv_th_new_final_diag = sv_th_new_final_diag[:len(zbinsc)]\n",
    "\n",
    "nts = Nc.copy()\n",
    "nzt = Nzc.copy()\n",
    "nz,nt = nzt.shape\n",
    "\n",
    "# Removing types that don't have galaxies\n",
    "maskt = (np.sum(nzt,axis=0)>0.)\n",
    "nts = nts[maskt]\n",
    "nzt = nzt[:,maskt]\n",
    "\n",
    "# What is the redshift of each type?\n",
    "# Computing the mean redshift per type\n",
    "zmeant = np.zeros(nzt.shape[1])\n",
    "for i in range(nzt.shape[1]):\n",
    "    zmeant[i] = np.average(np.arange(len(zbinsc)),weights=nzt.T[i])\n",
    "zmeant = np.rint(zmeant)\n",
    "\n",
    "#sv_th_v2 = np.load('/global/cscratch1/sd/alexalar/desy3data/marco_sv_v2/sv_th_v2.npy')\n",
    "\n",
    "varn_th = 1 + np.sum(nzt,axis=1)*sv_th\n",
    "#varn_th_deep_v2 = 1 + np.sum(nzt/np.sum(nzt,axis=0) * nts,axis=1)*sv_th_v2\n",
    "varn_th_deep_v2 = 1 + np.sum(nzt/np.sum(nzt,axis=0) * nts,axis=1)*sv_th_new_final_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b1c06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nzT(nzti, njoin, plot=False):\n",
    "    zmeanti = np.zeros(nzti.shape[1])\n",
    "    for i in range(nzti.shape[1]):\n",
    "        try: zmeanti[i] = np.average(np.arange(len(zbinsc)),weights=nzti.T[i])\n",
    "        except: zmeanti[i] = np.random.randint(len(zbinsc))\n",
    "    zmeanti = np.rint(zmeant)\n",
    "\n",
    "    nzTi = np.zeros((len(zbinsc),int(len(zbinsc)/njoin)))\n",
    "    for i in range(int(len(zbinsc)/njoin)):\n",
    "        nzTi[:,i] = np.sum(nzti[:,((zmeant>=njoin*i)&(zmeant<njoin*i+njoin))],axis=1)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        for i in range(int(len(zbinsc)/njoin)):\n",
    "            plt.plot(zbinsc,nzTi[:,i])\n",
    "        plt.show()\n",
    "    \n",
    "    return nzTi\n",
    "\n",
    "def make_nT(nzti, nti, njoin):\n",
    "    zmeanti = np.zeros(nzti.shape[1])\n",
    "    for i in range(nzti.shape[1]):\n",
    "        try: zmeanti[i] = np.average(np.arange(len(zbinsc)),weights=nzti.T[i])\n",
    "        except: zmeanti[i] = np.random.randint(len(zbinsc))\n",
    "    zmeanti = np.rint(zmeant)\n",
    "\n",
    "    nTi = np.zeros(int(len(zbinsc)/njoin))\n",
    "    for i in range(int(len(zbinsc)/njoin)):\n",
    "        nTi[i] = np.sum(nti[((zmeant>=njoin*i)&(zmeant<njoin*i+njoin))])\n",
    "    return nTi\n",
    "\n",
    "def corr_metric(pzT):\n",
    "    pzT = pzT/pzT.sum()\n",
    "    overlap = np.zeros((pzT.shape[1],pzT.shape[1]))\n",
    "    for i in range(pzT.shape[1]):\n",
    "        for j in range(pzT.shape[1]):\n",
    "            overlap[i,j] = np.sum(pzT[:,i]*pzT[:,j])\n",
    "    overlap = overlap/np.diagonal(overlap)[:,None]\n",
    "    metric = np.linalg.det(overlap)**(float(pzT.shape[1])/float(len(zbinsc)))\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff367929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation metric = 0.138\n",
      "/project/chihway/raulteixeira/data/SOMPZ_optPrime_spec_PAU_C30elsewhere_deep_balrog_January14.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/jobs/33065071/ipykernel_224404/1612219454.py:44: RuntimeWarning: invalid value encountered in divide\n",
      "  fcchat_0 /= np.multiply.outer(np.sum(fcchat_0,axis=1), np.sum(fcchat_0,axis=0))\n",
      "/tmp/jobs/33065071/ipykernel_224404/1612219454.py:45: RuntimeWarning: invalid value encountered in divide\n",
      "  fcchat_1 /= np.multiply.outer(np.sum(fcchat_1,axis=1), np.sum(fcchat_1,axis=0))\n",
      "/tmp/jobs/33065071/ipykernel_224404/1612219454.py:46: RuntimeWarning: invalid value encountered in divide\n",
      "  fcchat_2 /= np.multiply.outer(np.sum(fcchat_2,axis=1), np.sum(fcchat_2,axis=0))\n",
      "/tmp/jobs/33065071/ipykernel_224404/1612219454.py:47: RuntimeWarning: invalid value encountered in divide\n",
      "  fcchat_3 /= np.multiply.outer(np.sum(fcchat_3,axis=1), np.sum(fcchat_3,axis=0))\n"
     ]
    }
   ],
   "source": [
    "### Decide which phenotypes go to which superphenotype\n",
    "########\n",
    "### Choose number of superphenotypes\n",
    "nT = 6\n",
    "########\n",
    "bins = {str(b):[] for b in range(nT)}\n",
    "j = 0 \n",
    "sumbin = 0\n",
    "nTs = np.zeros(len(zbinsc))\n",
    "for i in range(len(zbinsc)):\n",
    "    sumbin += np.sum(nzt[:,((zmeant==i))],axis=1).sum()\n",
    "    nTs[i] = np.sum(nzt[:,((zmeant==i))],axis=1).sum()\n",
    "    if (sumbin <= np.sum(nzt)/(nT-1))|(j==nT-1):\n",
    "        bins[str(j)].append(i)\n",
    "        #continue\n",
    "    else:\n",
    "        j += 1\n",
    "        bins[str(j)].append(i)\n",
    "        sumbin = np.sum(nzt[:,((zmeant==i))],axis=1).sum()\n",
    "        \n",
    "        \n",
    "### Compute p(T), p(z,T) for the superphenotypes\n",
    "nzTi = np.zeros((len(zbinsc),nT))\n",
    "nTi = np.zeros((nT))\n",
    "for i in range(nT):\n",
    "    nzTi[:,i] = np.sum(make_nzT(nzt,1,False)[:,bins[str(i)]],axis=1)\n",
    "    nTi[i] = np.sum(make_nT(nzt,nts,1)[bins[str(i)]])\n",
    "    \n",
    "print ('Correlation metric = %.3f'%corr_metric(nzTi))\n",
    "\n",
    "\n",
    "#####################################\n",
    "### Sampling.\n",
    "### Prepare matrices for efficient sampling.\n",
    "#####################################\n",
    "\n",
    "### Define p(c,chat|bhat)/[p(c|bhat)p(chat|bhat)] --  conditioned on tomographic bin\n",
    "fcchat = pc_chat.T/pc_chat.sum()\n",
    "\n",
    "fcchat_0 = fcchat[tomo_bins_wide_modal_even[0]]\n",
    "fcchat_1 = fcchat[tomo_bins_wide_modal_even[1]]\n",
    "fcchat_2 = fcchat[tomo_bins_wide_modal_even[2]]\n",
    "fcchat_3 = fcchat[tomo_bins_wide_modal_even[3]]\n",
    "fcchat_0 /= np.multiply.outer(np.sum(fcchat_0,axis=1), np.sum(fcchat_0,axis=0))\n",
    "fcchat_1 /= np.multiply.outer(np.sum(fcchat_1,axis=1), np.sum(fcchat_1,axis=0))\n",
    "fcchat_2 /= np.multiply.outer(np.sum(fcchat_2,axis=1), np.sum(fcchat_2,axis=0))\n",
    "fcchat_3 /= np.multiply.outer(np.sum(fcchat_3,axis=1), np.sum(fcchat_3,axis=0))\n",
    "\n",
    "fcchat_0[~np.isfinite(fcchat_0)] = 0\n",
    "fcchat_1[~np.isfinite(fcchat_1)] = 0\n",
    "fcchat_2[~np.isfinite(fcchat_2)] = 0\n",
    "fcchat_3[~np.isfinite(fcchat_3)] = 0\n",
    "\n",
    "### Define p(chat|bhat) --  conditioned on tomographic bin\n",
    "fchat_0 = pchat[tomo_bins_wide_modal_even[0]]\n",
    "fchat_1 = pchat[tomo_bins_wide_modal_even[1]]\n",
    "fchat_2 = pchat[tomo_bins_wide_modal_even[2]]\n",
    "fchat_3 = pchat[tomo_bins_wide_modal_even[3]]\n",
    "\n",
    "z2Tmap = np.zeros((len(zmeant))).astype(int)\n",
    "for i in range(nT):\n",
    "    z2Tmap[np.isin(zmeant.astype(int),bins[str(i)])] = i\n",
    "    \n",
    "Fcchat_0 = fcchat_0*fchat_0[:,None]\n",
    "Fcchat_1 = fcchat_1*fchat_1[:,None]\n",
    "Fcchat_2 = fcchat_2*fchat_2[:,None]\n",
    "Fcchat_3 = fcchat_3*fchat_3[:,None]\n",
    "\n",
    "try:\n",
    "    print(save_h5)\n",
    "    store = pd.HDFStore(save_h5)\n",
    "    store['nzt'] = pd.DataFrame(nzt)\n",
    "    store['nzTi'] = pd.DataFrame(nzTi)\n",
    "    store['nTi'] = pd.Series(nTi)\n",
    "    store['nts'] = pd.Series(nts)\n",
    "    store['bincond_combined_0'] = pd.DataFrame(bincond_combined[:,:,maskt][0])\n",
    "    store['bincond_combined_1'] = pd.DataFrame(bincond_combined[:,:,maskt][1])\n",
    "    store['bincond_combined_2'] = pd.DataFrame(bincond_combined[:,:,maskt][2])\n",
    "    store['bincond_combined_3'] = pd.DataFrame(bincond_combined[:,:,maskt][3])\n",
    "    store['R_combined_0'] = pd.DataFrame(Rt_combined[:,:,maskt][0])\n",
    "    store['R_combined_1'] = pd.DataFrame(Rt_combined[:,:,maskt][1])\n",
    "    store['R_combined_2'] = pd.DataFrame(Rt_combined[:,:,maskt][2])\n",
    "    store['R_combined_3'] = pd.DataFrame(Rt_combined[:,:,maskt][3])\n",
    "    store['sv_th'] = pd.Series(sv_th)\n",
    "    store['sv_th_deep'] = pd.Series(sv_th_new_final_diag)\n",
    "    store['varn_th'] = pd.Series(varn_th)\n",
    "    store['varn_th_deep'] = pd.Series(varn_th_deep_v2)\n",
    "    store['fcchat_0'] = pd.DataFrame(fcchat_0[:,maskt])\n",
    "    store['fcchat_1'] = pd.DataFrame(fcchat_1[:,maskt])\n",
    "    store['fcchat_2'] = pd.DataFrame(fcchat_2[:,maskt])\n",
    "    store['fcchat_3'] = pd.DataFrame(fcchat_3[:,maskt])\n",
    "    store['fchat_0'] = pd.Series(fchat_0)\n",
    "    store['fchat_1'] = pd.Series(fchat_1)\n",
    "    store['fchat_2'] = pd.Series(fchat_2)\n",
    "    store['fchat_3'] = pd.Series(fchat_3)\n",
    "    store['z2Tmap'] = pd.Series(z2Tmap)\n",
    "    store['maskt'] = pd.Series(maskt)\n",
    "    store.close()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50873333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert False\n",
    "\n",
    "def return_nzsamples_fromfzt(fzt_dummy):\n",
    "    fzt = np.zeros((4096,len(zbinsc))).T\n",
    "    fzt[:,maskt] = fzt_dummy.T\n",
    "\n",
    "    ### Multiply the f_{zc} by:\n",
    "    ### - Rzt: the average weight (includes response and shear weight).\n",
    "    ### - gzt: the fraction probability for each tomographic bin.\n",
    "    ### to add the bin condition and the average response and shear weights.\n",
    "    fzt_0 = fzt * bincond_combined[0] * Rt_combined[0]\n",
    "    fzt_1 = fzt * bincond_combined[1] * Rt_combined[1]\n",
    "    fzt_2 = fzt * bincond_combined[2] * Rt_combined[2]\n",
    "    fzt_3 = fzt * bincond_combined[3] * Rt_combined[3]\n",
    "\n",
    "    fzt_0 /= np.sum(fzt_0)\n",
    "    fzt_1 /= np.sum(fzt_1)\n",
    "    fzt_2 /= np.sum(fzt_2)\n",
    "    fzt_3 /= np.sum(fzt_3)\n",
    "\n",
    "    fzt_0[~np.isfinite(fzt_0)] = 0\n",
    "    fzt_1[~np.isfinite(fzt_1)] = 0\n",
    "    fzt_2[~np.isfinite(fzt_2)] = 0\n",
    "    fzt_3[~np.isfinite(fzt_3)] = 0\n",
    "\n",
    "    ### SOMPZ: Equals Eq.2 in https://www.overleaf.com/project/5e8b5a7d3431a1000126471a\n",
    "    nz_0 = np.einsum('zt,dt->z', fzt_0, Fcchat_0)\n",
    "    nz_1 = np.einsum('zt,dt->z', fzt_1, Fcchat_1)\n",
    "    nz_2 = np.einsum('zt,dt->z', fzt_2, Fcchat_2)\n",
    "    nz_3 = np.einsum('zt,dt->z', fzt_3, Fcchat_3)\n",
    "\n",
    "    nz_0 /= nz_0.sum()\n",
    "    nz_1 /= nz_1.sum()\n",
    "    nz_2 /= nz_2.sum()\n",
    "    nz_3 /= nz_3.sum()\n",
    "\n",
    "    nz_samples = np.array([nz_0, nz_1, nz_2, nz_3])\n",
    "    return nz_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f3de72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = sum(maskt)\n",
    "nz=len(zbinsc)\n",
    "N_Tcz_Rsample = np.zeros((nT,nt,nz))\n",
    "for i in range(nT):\n",
    "    sel = z2Tmap==i\n",
    "    N_Tcz_Rsample[i, sel] = nzt.T[sel]\n",
    "\n",
    "N_Tc_Dsample = np.zeros((nT,nt))\n",
    "for i in range(nT):\n",
    "    sel = z2Tmap==i\n",
    "    N_Tc_Dsample[i, sel] = nts[sel]\n",
    "    \n",
    "    \n",
    "alpha = 1e-300\n",
    "\n",
    "N_T_Rsample = np.sum(N_Tcz_Rsample, axis=(1,2))\n",
    "N_z_Rsample = np.sum(N_Tcz_Rsample, axis=(0,1))\n",
    "N_Tz_Rsample = np.sum(N_Tcz_Rsample, axis=(1))\n",
    "N_cz_Rsample = np.sum(N_Tcz_Rsample, axis=(0))\n",
    "\n",
    "N_T_Dsample = np.sum(N_Tc_Dsample, axis=(1))\n",
    "N_c_Dsample = np.sum(N_Tc_Dsample, axis=(0))\n",
    "\n",
    "lambda_z_step1 = varn_th_deep_v2.copy()\n",
    "lambda_z_step2 = varn_th.copy()\n",
    "lambda_mean = np.sum(lambda_z_step1*N_z_Rsample/N_z_Rsample.sum())\n",
    "lambda_mean_R = np.sum(lambda_z_step2*N_z_Rsample/N_z_Rsample.sum())\n",
    "lambda_T = np.array([np.sum(lambda_z_step2 * x/x.sum()) for x in N_Tz_Rsample])\n",
    "\n",
    "onecell = np.sum(N_cz_Rsample>0,axis=1) == 1\n",
    "N_cz_Rsample_onecell = (N_cz_Rsample/np.sum(N_cz_Rsample,axis=1)[:,None])[onecell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7918bd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m Nc \u001b[38;5;241m=\u001b[39m return_Nc(spec_data)\n\u001b[1;32m      4\u001b[0m Nc_0 \u001b[38;5;241m=\u001b[39m return_Nc(spec_data[spec_data\u001b[38;5;241m.\u001b[39mcell_wide_unsheared\u001b[38;5;241m.\u001b[39misin(tomo_bins_wide_modal_even[\u001b[38;5;241m0\u001b[39m])])\n\u001b[0;32m----> 5\u001b[0m Nc_1 \u001b[38;5;241m=\u001b[39m \u001b[43mreturn_Nc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mspec_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcell_wide_unsheared\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtomo_bins_wide_modal_even\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m Nc_2 \u001b[38;5;241m=\u001b[39m return_Nc(spec_data[spec_data\u001b[38;5;241m.\u001b[39mcell_wide_unsheared\u001b[38;5;241m.\u001b[39misin(tomo_bins_wide_modal_even[\u001b[38;5;241m2\u001b[39m])])\n\u001b[1;32m      7\u001b[0m Nc_3 \u001b[38;5;241m=\u001b[39m return_Nc(spec_data[spec_data\u001b[38;5;241m.\u001b[39mcell_wide_unsheared\u001b[38;5;241m.\u001b[39misin(tomo_bins_wide_modal_even[\u001b[38;5;241m3\u001b[39m])])\n",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m, in \u001b[0;36mreturn_Nc\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreturn_Nc\u001b[39m(df):\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    - This function returns the counts Nc=N(c) in each cell c.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    - The input is a pandas Dataframe containing a deep sample. \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    to weight the counts of each galaxy in N(c).\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     redshift_sample \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minjection_counts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrue_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcell_deep\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrue_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     35\u001b[0m     unique_id, unique_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(df\u001b[38;5;241m.\u001b[39mtrue_id\u001b[38;5;241m.\u001b[39mvalues, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m     redshift_sample \u001b[38;5;241m=\u001b[39m redshift_sample\u001b[38;5;241m.\u001b[39mmerge(pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_id\u001b[39m\u001b[38;5;124m'\u001b[39m:unique_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_counts\u001b[39m\u001b[38;5;124m'\u001b[39m:unique_counts}),on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1269\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1266\u001b[0m func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[1;32m   1268\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args, kwargs)\n\u001b[0;32m-> 1269\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/apply.py:160\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(arg):\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/apply.py:496\u001b[0m, in \u001b[0;36mApply.apply_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_names:\n\u001b[1;32m    495\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\n\u001b[0;32m--> 496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_aggregate_string_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/apply.py:565\u001b[0m, in \u001b[0;36mApply._try_aggregate_string_function\u001b[0;34m(self, obj, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(f):\n\u001b[0;32m--> 565\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;66;03m# people may try to aggregate on a non-callable attribute\u001b[39;00m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;66;03m# but don't let them think they can pass args to it\u001b[39;00m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1855\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[1;32m   1854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1855\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1856\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1507\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1507\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1508\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[1;32m   1509\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/internals/managers.py:1506\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1504\u001b[0m             result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m   1505\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1506\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result_blocks) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/internals/blocks.py:329\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    325\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1490\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1488\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marray_func\u001b[39m(values: ArrayLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[1;32m   1489\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1490\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maggregate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1498\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m         \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m         \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/groupby/ops.py:955\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;124;03mReturns the values of a cython operation.\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m kind \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 955\u001b[0m cy_op \u001b[38;5;241m=\u001b[39m WrappedCythonOp(kind\u001b[38;5;241m=\u001b[39mkind, how\u001b[38;5;241m=\u001b[39mhow, has_dropped_na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_dropped_na\u001b[49m)\n\u001b[1;32m    957\u001b[0m ids, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_info\n\u001b[1;32m    958\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/groupby/ops.py:869\u001b[0m, in \u001b[0;36mBaseGrouper.has_dropped_na\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhas_dropped_na\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    866\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;124;03m    Whether grouper has null value(s) that are dropped.\u001b[39;00m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m((\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_info\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many())\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/groupby/ops.py:873\u001b[0m, in \u001b[0;36mBaseGrouper.group_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgroup_info\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m--> 873\u001b[0m     comp_ids, obs_group_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_compressed_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m     ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(obs_group_ids)\n\u001b[1;32m    876\u001b[0m     comp_ids \u001b[38;5;241m=\u001b[39m ensure_platform_int(comp_ids)\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/groupby/ops.py:897\u001b[0m, in \u001b[0;36mBaseGrouper._get_compressed_codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;66;03m# FIXME: compress_group_index's second return value is int64, not intp\u001b[39;00m\n\u001b[1;32m    896\u001b[0m ping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 897\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodes\u001b[49m, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(ping\u001b[38;5;241m.\u001b[39mgroup_index), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:671\u001b[0m, in \u001b[0;36mGrouping.codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39msignedinteger]:\n\u001b[0;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_codes_and_uniques\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:780\u001b[0m, in \u001b[0;36mGrouping._codes_and_uniques\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    775\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uniques\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH35667, replace dropna=False with use_na_sentinel=False\u001b[39;00m\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"Union[\u001b[39;00m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# ndarray[Any, Any], Index]\", variable has type \"Categorical\")\u001b[39;00m\n\u001b[0;32m--> 780\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouping_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dropna\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/algorithms.py:780\u001b[0m, in \u001b[0;36mfactorize\u001b[0;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[1;32m    778\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[0;32m--> 780\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    787\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[1;32m    788\u001b[0m         uniques,\n\u001b[1;32m    789\u001b[0m         codes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    792\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    793\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/raul/lib/python3.11/site-packages/pandas/core/algorithms.py:581\u001b[0m, in \u001b[0;36mfactorize_array\u001b[0;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    578\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[1;32m    580\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[0;32m--> 581\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[1;32m    590\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def draw_3sdir_onlyR():\n",
    "    \n",
    "    ### step1\n",
    "    f_T = np.random.dirichlet(N_T_Rsample/lambda_mean_R+alpha)\n",
    "\n",
    "    ### step2\n",
    "    f_z_T = np.array([np.random.dirichlet(x/lambda_T[i]+alpha) for i,x in enumerate(N_Tz_Rsample)])\n",
    "\n",
    "    ### step3\n",
    "    f_cz_Rsample = np.random.dirichlet(N_cz_Rsample.reshape(np.prod(N_cz_Rsample.shape))+alpha).reshape(N_cz_Rsample.shape)\n",
    "    f_cz = np.zeros((nt,nz))\n",
    "    for k in range(N_Tcz_Rsample.shape[0]):\n",
    "        sel = z2Tmap==k\n",
    "        dummy = f_cz_Rsample[sel] \n",
    "        dummy = dummy/np.sum(dummy,axis=0)\n",
    "        dummy[np.isnan(dummy)] = 0\n",
    "        f_cz[sel] += np.einsum('cz,z->cz', dummy, f_z_T[k])* f_T[k]\n",
    "        \n",
    "    return f_cz\n",
    "\n",
    "\n",
    "def draw_3sdir_newmethod():\n",
    "    ### step1\n",
    "    f_T = np.random.dirichlet(N_T_Dsample/lambda_mean+alpha)\n",
    "\n",
    "    ### step2\n",
    "    f_cT = np.zeros(nt)\n",
    "    for k in range(nT):\n",
    "        sel = z2Tmap==k\n",
    "        f_cT[sel] = np.random.dirichlet(N_Tc_Dsample[k,sel]+alpha) * f_T[k]\n",
    "        \n",
    "    ### step3\n",
    "    f_cz = draw_3sdir_onlyR()\n",
    "    f_z_c = f_cz/np.sum(f_cz,axis=1)[:,None]\n",
    "    f_z_c[onecell] = N_cz_Rsample_onecell\n",
    "    \n",
    "    ### compute f_{zc}\n",
    "    f_cz = f_z_c * f_cT[:,None]\n",
    "    return f_cz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def aux_fun(i):\n",
    "    np.random.seed()\n",
    "    #t0 = time.time()\n",
    "    nz_samples_newmethod = np.zeros((Nsamples,4, len(zbinsc)))\n",
    "\n",
    "    #t0 = time.time()\n",
    "    for i_sample in range(Nsamples):\n",
    "        f_zt = draw_3sdir_newmethod()\n",
    "        nz_samples_newmethod[i_sample] = return_nzsamples_fromfzt(f_zt)\n",
    "\n",
    "    #t1 = time.time()\n",
    "    #print(t1-t0)\n",
    "    return nz_samples_newmethod  \n",
    "        \n",
    "    \n",
    "p = Pool(28) #changed to 28 for midway --Raul (original: 64)\n",
    "nz_samples_newmethod = np.concatenate(p.map(aux_fun, range(28)), axis=0) #changed to 28 for midway --Raul (original: 64)\n",
    "p.terminate()\n",
    "\n",
    "sel = np.sum(np.isnan(nz_samples_newmethod),axis=(1,2))==0\n",
    "nz_samples_newmethod = nz_samples_newmethod[sel]\n",
    "\n",
    "np.save(outpath+'nz_samples_newmethod.npy', nz_samples_newmethod)\n",
    "\n",
    "def draw_3sdir_step3_p_zT_onlyR():\n",
    "    \n",
    "    ### step1\n",
    "    f_T = np.random.dirichlet(N_T_Dsample/lambda_mean+alpha)\n",
    "\n",
    "    ### step2\n",
    "    f_z_T = np.array([np.random.dirichlet(x/lambda_T[i]+alpha) for i,x in enumerate(N_Tz_Rsample)])\n",
    "\n",
    "    ### step3\n",
    "    f_cz_Rsample = np.random.dirichlet(N_cz_Rsample.reshape(np.prod(N_cz_Rsample.shape))+alpha).reshape(N_cz_Rsample.shape)\n",
    "    f_cz = np.zeros((nt,nz))\n",
    "    for k in range(N_Tcz_Rsample.shape[0]):\n",
    "        sel = z2Tmap==k\n",
    "        dummy = f_cz_Rsample[sel] \n",
    "        dummy = dummy/np.sum(dummy,axis=0)\n",
    "        dummy[np.isnan(dummy)] = 0\n",
    "        f_cz[sel] += np.einsum('cz,z->cz', dummy, f_z_T[k])* f_T[k]\n",
    "        \n",
    "    return f_cz\n",
    "    \n",
    "def aux_fun_2(i):\n",
    "    np.random.seed()\n",
    "    #t0 = time.time()\n",
    "    nz_samples_newmethod = np.zeros((Nsamples,4, len(zbinsc)))\n",
    "\n",
    "    t0 = time.time()\n",
    "    for i_sample in range(Nsamples):\n",
    "        f_zt = draw_3sdir_step3_p_zT_onlyR()\n",
    "        nz_samples_newmethod[i_sample] = return_nzsamples_fromfzt(f_zt)\n",
    "\n",
    "    #t1 = time.time()\n",
    "    #print(t1-t0)\n",
    "    return nz_samples_newmethod \n",
    "\n",
    "p = Pool(28) #changed to 28 for midway --Raul (original: 64)\n",
    "nz_samples = np.concatenate(p.map(aux_fun_2, range(28)), axis=0) #changed to 28 for midway --Raul (original: 64)\n",
    "p.terminate()\n",
    "\n",
    "sel = np.sum(np.isnan(nz_samples),axis=(1,2))==0\n",
    "nz_samples = nz_samples[sel]\n",
    "\n",
    "np.save(outpath+'nz_samples.npy', nz_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64d08a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
